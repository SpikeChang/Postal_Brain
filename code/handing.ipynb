{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlng2_manhattan_distance(loc1, loc2):\n",
    "\n",
    "    lat_lon_1 = np.radians(loc1)\n",
    "    lat_lon_2 = np.radians(loc2)\n",
    "    d_lat_lon = np.abs(lat_lon_1- lat_lon_2)\n",
    "    r = 6373.0\n",
    "    a_lat_lon = np.sin(d_lat_lon / 2.0) **2\n",
    "    c = 2 * np.arctan2(np.sqrt(a_lat_lon), np.sqrt(1 - a_lat_lon))\n",
    "    c = r * c\n",
    "    c = np.sum(c, axis=1)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#日期，业务种类，重量，揽投机构，道段(揽收只有业务员信息，没有道段故不收入)\n",
    "print(\"0\")\n",
    "#读取揽收数据\n",
    "data_lanshou = pd.read_csv('江门揽收数据.csv', encoding='gb18030', usecols=[0,1,3,6,8])\n",
    "data_lanshou = data_lanshou[['D_CLCT_DATE','V_MAIL_CODE','V_BUSI_TYPE', 'F_WEIGH_WEIGHT', 'V_CLCT_ORG_CODE']]#调整一下顺序\n",
    "data_lanshou['D_CLCT_DATE'] = pd.to_datetime(data_lanshou['D_CLCT_DATE'])\n",
    "#加入经纬度\n",
    "data_lanshou_ = pd.read_csv('coord/lanshou.csv', encoding='gb18030', usecols=[1,2])\n",
    "data_lanshou['lng'] = data_lanshou_['lng']\n",
    "data_lanshou['lat'] = data_lanshou_['lat']\n",
    "#揽收默认的列属性不太一样，改成与投递一致\n",
    "new_cols = [\"投递日期\",\"邮件号\",\"业务种类\",\"重量\",\"投递机构\",\"lng\",\"lat\"]\n",
    "data_lanshou.columns = new_cols\n",
    "data_lanshou['邮件号'].apply(str)\n",
    "print(\"1\")\n",
    "#读取投递数据1\n",
    "data_toudi21 = pd.read_csv('toudi_21.csv', encoding='gb18030', usecols=[0,1,2,3,4,7])\n",
    "data_toudi21['道段'] = data_toudi21['道段'].str.split(' ', expand=True)[0]\n",
    "data_toudi21['投递日期'] = pd.to_datetime(data_toudi21['投递日期'])\n",
    "#加入经纬度\n",
    "data_toudi21_  = pd.read_csv('coord/toudi_21.csv', encoding='gb18030', usecols=[1,2])\n",
    "data_toudi21['lng'] = data_toudi21_['lng']\n",
    "data_toudi21['lat'] = data_toudi21_['lat']\n",
    "print(\"2\")\n",
    "#读取投递数据2\n",
    "data_toudi22 = pd.read_csv('toudi_22.csv', encoding='gb18030', usecols=[0,1,2,3,4,7])\n",
    "data_toudi22['道段'] = data_toudi22['道段'].str.split(' ', expand=True)[0]\n",
    "data_toudi22['投递日期'] = pd.to_datetime(data_toudi22['投递日期'])\n",
    "#加入经纬度\n",
    "data_toudi22_  = pd.read_csv('coord/toudi_21.csv', encoding='gb18030', usecols=[1,2])\n",
    "data_toudi22['lng'] = data_toudi22_['lng']\n",
    "data_toudi22['lat'] = data_toudi22_['lat']\n",
    "print(\"3\")\n",
    "#读取投递数据3\n",
    "data_toudi206 = pd.read_csv('toudi_206.csv', encoding='gb18030', usecols=[0,1,2,3,4,7])\n",
    "data_toudi206['道段'] = data_toudi206['道段'].str.split(' ', expand=True)[0]\n",
    "data_toudi206['投递日期'] = pd.to_datetime(data_toudi206['投递日期'])\n",
    "#加入经纬度\n",
    "data_toudi206_  = pd.read_csv('coord/toudi_21.csv', encoding='gb18030', usecols=[1,2])\n",
    "data_toudi206['lng'] = data_toudi206_['lng']\n",
    "data_toudi206['lat'] = data_toudi206_['lat']\n",
    "print(\"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将不存在的部门排除\n",
    "departments = pd.read_excel('江门补充资料/江门机构.xlsx', usecols=[3,11,12])\n",
    "temp = departments['机构代码'].tolist()\n",
    "\n",
    "# data_lanshou\n",
    "bools = []\n",
    "for row in data_lanshou.values:\n",
    "    bools.append(row[4] in temp)\n",
    "data_lanshou = data_lanshou.loc[bools]\n",
    "\n",
    "# data_toudi21\n",
    "bools = []\n",
    "for row in data_toudi21.values:\n",
    "    bools.append(row[4] in temp)\n",
    "data_toudi21 = data_toudi21.loc[bools]\n",
    "\n",
    "# data_toudi22\n",
    "bools = []\n",
    "for row in data_toudi22.values:\n",
    "    bools.append(row[4] in temp)\n",
    "data_toudi22 = data_toudi22.loc[bools]\n",
    "\n",
    "# data_toudi206\n",
    "bools = []\n",
    "for row in data_toudi206.values:\n",
    "    bools.append(row[4] in temp)\n",
    "data_toudi206 = data_toudi206.loc[bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude为不需要的日期列表，下述代码将周末的数据排除\n",
    "exclude = [\"2020-08-01\",\"2020-08-02\",\"2020-08-08\",\"2020-08-09\",\"2020-08-15\",\"2020-08-16\",\"2020-08-22\",\"2020-08-23\",\"2020-08-29\",\"2020-08-30\"]\n",
    "\n",
    "bools = []\n",
    "for row in data_lanshou.values:\n",
    "    bools.append(str(row[0].date()) not in exclude)\n",
    "data_lanshou = data_lanshou.loc[bools]\n",
    "\n",
    "bools = []\n",
    "for row in data_toudi21.values:\n",
    "    bools.append(str(row[0].date()) not in exclude)\n",
    "data_toudi21 = data_toudi21.loc[bools]\n",
    "\n",
    "bools = []\n",
    "for row in data_toudi22.values:\n",
    "    bools.append(str(row[0].date()) not in exclude)\n",
    "data_toudi22 = data_toudi22.loc[bools]\n",
    "    \n",
    "bools = []\n",
    "for row in data_toudi206.values:\n",
    "    bools.append(str(row[0].date()) not in exclude)\n",
    "data_toudi206 = data_toudi206.loc[bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558886\n",
      "1151181\n",
      "1430160\n"
     ]
    }
   ],
   "source": [
    "#重量归一化\n",
    "#求所有揽收数据的重量均值和标准差\n",
    "temp = data_lanshou.loc[:,'重量']\n",
    "mean = temp.mean()\n",
    "std = temp.std()\n",
    "temp = temp.map(lambda x: 50+10*(x-mean)/std)\n",
    "data_lanshou.loc[:,'重量'] = temp\n",
    "\n",
    "#求所有投递数据的重量均值和标准差\n",
    "temp = data_toudi21.loc[:,'重量'].values\n",
    "print(len(temp))\n",
    "temp = np.insert(temp,1,data_toudi22.loc[:,'重量'].values)\n",
    "print(len(temp))\n",
    "temp = np.insert(temp,1,data_toudi206.loc[:,'重量'].values)\n",
    "print(len(temp))\n",
    "mean = np.nanmean(temp)\n",
    "std = np.nanstd(temp)\n",
    "\n",
    "data_toudi21['重量'].fillna(mean, inplace=True)\n",
    "data_toudi22['重量'].fillna(mean, inplace=True)\n",
    "data_toudi206['重量'].fillna(mean, inplace=True)\n",
    "\n",
    "temp = data_toudi21['重量']\n",
    "temp = temp.map(lambda x: 50+10*(x-mean)/std)\n",
    "data_toudi21.loc[:,'重量'] = temp\n",
    "\n",
    "temp = data_toudi22['重量']\n",
    "temp = temp.map(lambda x: 50+10*(x-mean)/std)\n",
    "data_toudi22.loc[:,'重量'] = temp\n",
    "\n",
    "temp = data_toudi206['重量']\n",
    "temp = temp.map(lambda x: 50+10*(x-mean)/std)\n",
    "data_toudi206.loc[:,'重量'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去除外省数据以及缺失数据，此处直接将经纬度大的离谱的和nan去除\n",
    "temp = data_lanshou.loc[data_lanshou['lng'].isnull().values.tolist()]\n",
    "data_lanshou = data_lanshou.drop(temp.index, axis=0)\n",
    "temp = data_lanshou.loc[(data_lanshou['lng']>114) | (data_lanshou['lng']<111)]\n",
    "data_lanshou = data_lanshou.drop(temp.index)\n",
    "temp = data_lanshou.loc[(data_lanshou['lat']>23) | (data_lanshou['lat']<21)]\n",
    "data_lanshou = data_lanshou.drop(temp.index)\n",
    "\n",
    "temp = data_toudi21.loc[data_toudi21['lng'].isnull().values.tolist()]\n",
    "data_toudi21 = data_toudi21.drop(temp.index, axis=0)\n",
    "temp = data_toudi21.loc[(data_toudi21['lng']>114) | (data_toudi21['lng']<111)]\n",
    "data_toudi21 = data_toudi21.drop(temp.index)\n",
    "temp = data_toudi21.loc[(data_toudi21['lat']>23) | (data_toudi21['lat']<21)]\n",
    "data_toudi21 = data_toudi21.drop(temp.index)\n",
    "\n",
    "temp = data_toudi22.loc[data_toudi22['lng'].isnull().values.tolist()]\n",
    "data_toudi22 = data_toudi22.drop(temp.index, axis=0)\n",
    "temp = data_toudi22.loc[(data_toudi22['lng']>114) | (data_toudi22['lng']<111)]\n",
    "data_toudi22 = data_toudi22.drop(temp.index)\n",
    "temp = data_toudi22.loc[(data_toudi22['lat']>23) | (data_toudi22['lat']<21)]\n",
    "data_toudi22 = data_toudi22.drop(temp.index)\n",
    "\n",
    "temp = data_toudi206.loc[data_toudi206['lng'].isnull().values.tolist()]\n",
    "data_toudi206 = data_toudi206.drop(temp.index, axis=0)\n",
    "temp = data_toudi206.loc[(data_toudi206['lng']>114) | (data_toudi206['lng']<111)]\n",
    "data_toudi206 = data_toudi206.drop(temp.index)\n",
    "temp = data_toudi206.loc[(data_toudi206['lat']>23) | (data_toudi206['lat']<21)]\n",
    "data_toudi206 = data_toudi206.drop(temp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "departments = pd.read_excel('江门补充资料/江门机构.xlsx', usecols=[3,11,12])\n",
    "#计算距离\n",
    "data_lanshou['dist'] = ''\n",
    "for i in range(len(departments)):\n",
    "    temp = data_lanshou.loc[data_lanshou['投递机构'] == departments.loc[i,:][0], ['lat','lng']]\n",
    "    dist = latlng2_manhattan_distance(np.array(departments.loc[i,:][1:3]), np.array(temp))\n",
    "    data_lanshou.loc[data_lanshou['投递机构'] == departments.loc[i,:][0], 'dist'] = dist\n",
    "    \n",
    "data_toudi21['dist'] = ''\n",
    "for i in range(len(departments)):\n",
    "    temp = data_toudi21.loc[data_toudi21['投递机构'] == departments.loc[i,:][0], ['lat','lng']]\n",
    "    dist = latlng2_manhattan_distance(np.array(departments.loc[i,:][1:3]), np.array(temp))\n",
    "    data_toudi21.loc[data_toudi21['投递机构'] == departments.loc[i,:][0], 'dist'] = dist\n",
    "    \n",
    "data_toudi22['dist'] = ''\n",
    "for i in range(len(departments)):\n",
    "    temp = data_toudi22.loc[data_toudi22['投递机构'] == departments.loc[i,:][0], ['lat','lng']]\n",
    "    dist = latlng2_manhattan_distance(np.array(departments.loc[i,:][1:3]), np.array(temp))\n",
    "    data_toudi22.loc[data_toudi22['投递机构'] == departments.loc[i,:][0], 'dist'] = dist\n",
    "    \n",
    "data_toudi206['dist'] = ''\n",
    "for i in range(len(departments)):\n",
    "    temp = data_toudi206.loc[data_toudi206['投递机构'] == departments.loc[i,:][0], ['lat','lng']]\n",
    "    dist = latlng2_manhattan_distance(np.array(departments.loc[i,:][1:3]), np.array(temp))\n",
    "    data_toudi206.loc[data_toudi206['投递机构'] == departments.loc[i,:][0], 'dist'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#代收和高端业务增加难度系数\n",
    "\n",
    "#寻找快包\n",
    "bools = data_lanshou['邮件号'].str.contains(\"^1.*8[0-9]$\",na=False)\n",
    "data_lanshou.loc[bools,'业务种类'] = \"代收\"\n",
    "\n",
    "bools = data_toudi21['邮件号'].str.contains(\"^1.*8[0-9]$\",na=False)\n",
    "data_toudi21.loc[bools,'业务种类'] = \"代收\"\n",
    "\n",
    "bools = data_toudi22['邮件号'].str.contains(\"^1.*8[0-9]$\",na=False)\n",
    "data_toudi22.loc[bools,'业务种类'] = \"代收\"\n",
    "\n",
    "bools = data_toudi206['邮件号'].str.contains(\"^1.*8[0-9]$\",na=False)\n",
    "data_toudi206.loc[bools,'业务种类'] = \"代收\"\n",
    "\n",
    "#设置代价\n",
    "data_lanshou.loc[data_lanshou['业务种类'] == \"代收\", \"业务种类\"] = 1.2\n",
    "data_lanshou.loc[data_lanshou['业务种类'] == \"高端政务\", \"业务种类\"] = 1.2\n",
    "data_lanshou.loc[data_lanshou['业务种类'] != 1.2, \"业务种类\"] = 1\n",
    "\n",
    "data_toudi21.loc[data_toudi21['业务种类'] == \"代收\", \"业务种类\"] = 1.2\n",
    "data_toudi21.loc[data_toudi21['业务种类'] == \"高端政务\", \"业务种类\"] = 1.2\n",
    "data_toudi21.loc[data_toudi21['业务种类'] != 1.2, \"业务种类\"] = 1\n",
    "\n",
    "data_toudi22.loc[data_toudi22['业务种类'] == \"代收\", \"业务种类\"] = 1.2\n",
    "data_toudi22.loc[data_toudi22['业务种类'] == \"高端政务\", \"业务种类\"] = 1.2\n",
    "data_toudi22.loc[data_toudi22['业务种类'] != 1.2, \"业务种类\"] = 1\n",
    "\n",
    "data_toudi206.loc[data_toudi206['业务种类'] == \"代收\", \"业务种类\"] = 1.2\n",
    "data_toudi206.loc[data_toudi206['业务种类'] == \"高端政务\", \"业务种类\"] = 1.2\n",
    "data_toudi206.loc[data_toudi206['业务种类'] != 1.2, \"业务种类\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按部门分开存储，放置于列表中\n",
    "lanshou = []\n",
    "toudi21 = []\n",
    "toudi22 = []\n",
    "toudi206 = []\n",
    "\n",
    "departments = pd.read_excel('江门补充资料/江门机构.xlsx', usecols=[3])\n",
    "for department in departments.values:\n",
    "    \n",
    "    batch = data_lanshou.loc[data_lanshou['投递机构']==int(department)]\n",
    "    lanshou.append(batch)\n",
    "    batch = data_toudi21.loc[data_toudi21['投递机构']==int(department)]\n",
    "    toudi21.append(batch)\n",
    "    batch = data_toudi22.loc[data_toudi22['投递机构']==int(department)]\n",
    "    toudi22.append(batch)\n",
    "    batch = data_toudi206.loc[data_toudi206['投递机构']==int(department)]\n",
    "    toudi206.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = [\"2020-08-03 00:00:00\", \"2020-08-03 12:00:00\", \"2020-08-04 00:00:00\", \"2020-08-04 12:00:00\", \"2020-08-05 00:00:00\",\n",
    "         \"2020-08-05 12:00:00\", \"2020-08-06 00:00:00\", \"2020-08-06 12:00:00\", \"2020-08-07 00:00:00\", \"2020-08-07 12:00:00\",\n",
    "         \"2020-08-12 00:00:00\", \"2020-08-12 12:00:00\", \"2020-08-13 00:00:00\", \"2020-08-13 12:00:00\", \"2020-08-14 00:00:00\",\n",
    "         \"2020-08-14 12:00:00\", \"2020-08-17 00:00:00\", \"2020-08-17 12:00:00\", \"2020-08-18 00:00:00\", \"2020-08-18 12:00:00\",\n",
    "         \"2020-08-19 00:00:00\", \"2020-08-19 12:00:00\", \"2020-08-20 00:00:00\", \"2020-08-20 12:00:00\", \"2020-08-21 00:00:00\",\n",
    "         \"2020-08-21 12:00:00\", \"2020-08-24 00:00:00\", \"2020-08-24 12:00:00\", \"2020-08-25 00:00:00\", \"2020-08-25 12:00:00\",\n",
    "         \"2020-08-26 00:00:00\", \"2020-08-26 12:00:00\", \"2020-08-27 00:00:00\", \"2020-08-27 12:00:00\", \"2020-08-28 00:00:00\",\n",
    "         \"2020-08-28 12:00:00\", \"2020-08-31 00:00:00\", \"2020-08-31 12:00:00\", \"2020-09-01 00:00:00\"]\n",
    "\n",
    "costs_lanshou = []#存放揽收各部门cost\n",
    "for department in lanshou:\n",
    "    cost = 0\n",
    "    for i in range(0,len(dates)-1):\n",
    "        #筛选日期\n",
    "        temp = department.loc[(department['投递日期'] > dates[i]) & (department['投递日期'] < dates[i+1])]\n",
    "        #计数同地点同时间的记录并去除重复\n",
    "        count = temp[['lng', 'lat', 'dist']].groupby(['lng', 'lat']).count()['dist'].values\n",
    "        temp = temp.drop_duplicates(subset=['lng','lat'],keep='first',inplace=False)\n",
    "        #计算\n",
    "        dist = np.array(temp['dist'], dtype=np.float32)\n",
    "        weight = np.array(temp['重量'], dtype=np.float32)\n",
    "        form = np.array(temp['业务种类'], dtype=np.float32)\n",
    "        assert(count.shape == dist.shape)\n",
    "        cost += np.sum(np.sqrt(count) * np.log2(dist) * weight * form, axis=0)\n",
    "    costs_lanshou.append(cost)\n",
    "\n",
    "costs_toudi21 = []#存放揽收各部门cost\n",
    "for department in toudi21:\n",
    "    cost = 0\n",
    "    for i in range(0,len(dates)-1):\n",
    "        #筛选日期\n",
    "        temp = department.loc[(department['投递日期'] > dates[i]) & (department['投递日期'] < dates[i+1])]\n",
    "        #计数同地点同时间的记录并去除重复\n",
    "        count = temp[['lng', 'lat', 'dist']].groupby(['lng', 'lat']).count()['dist'].values\n",
    "        temp = temp.drop_duplicates(subset=['lng','lat'],keep='first',inplace=False)\n",
    "        #计算\n",
    "        dist = np.array(temp['dist'], dtype=np.float32)\n",
    "        weight = np.array(temp['重量'], dtype=np.float32)\n",
    "        form = np.array(temp['业务种类'], dtype=np.float32)\n",
    "        assert(count.shape == dist.shape)\n",
    "        cost += np.sum(np.sqrt(count) * np.log2(dist) * weight * form, axis=0)\n",
    "    costs_toudi21.append(cost)\n",
    "    \n",
    "costs_toudi22 = []#存放揽收各部门cost\n",
    "for department in toudi22:\n",
    "    cost = 0\n",
    "    for i in range(0,len(dates)-1):\n",
    "        #筛选日期\n",
    "        temp = department.loc[(department['投递日期'] > dates[i]) & (department['投递日期'] < dates[i+1])]\n",
    "        #计数同地点同时间的记录并去除重复\n",
    "        count = temp[['lng', 'lat', 'dist']].groupby(['lng', 'lat']).count()['dist'].values\n",
    "        temp = temp.drop_duplicates(subset=['lng','lat'],keep='first',inplace=False)\n",
    "        #计算\n",
    "        dist = np.array(temp['dist'], dtype=np.float32)\n",
    "        weight = np.array(temp['重量'], dtype=np.float32)\n",
    "        form = np.array(temp['业务种类'], dtype=np.float32)\n",
    "        assert(count.shape == dist.shape)\n",
    "        cost += np.sum(np.sqrt(count) * np.log2(dist) * weight * form, axis=0)\n",
    "    costs_toudi22.append(cost)\n",
    "    \n",
    "costs_toudi206 = []#存放揽收各部门cost\n",
    "for department in toudi206:\n",
    "    cost = 0\n",
    "    for i in range(0,len(dates)-1):\n",
    "        #筛选日期\n",
    "        temp = department.loc[(department['投递日期'] > dates[i]) & (department['投递日期'] < dates[i+1])]\n",
    "        #计数同地点同时间的记录并去除重复\n",
    "        count = temp[['lng', 'lat', 'dist']].groupby(['lng', 'lat']).count()['dist'].values\n",
    "        temp = temp.drop_duplicates(subset=['lng','lat'],keep='first',inplace=False)\n",
    "        #计算\n",
    "        dist = np.array(temp['dist'], dtype=np.float32)\n",
    "        weight = np.array(temp['重量'], dtype=np.float32)\n",
    "        form = np.array(temp['业务种类'], dtype=np.float32)\n",
    "        assert(count.shape == dist.shape)\n",
    "        cost += np.sum(np.sqrt(count) * np.log2(dist) * weight * form, axis=0)\n",
    "    costs_toudi206.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "costs = np.array(costs_lanshou) + np.array(costs_toudi21) + np.array(costs_toudi22) + np.array(costs_toudi206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64850225.1129673\n",
      "129942716.56274758\n",
      "29748458.267988708\n",
      "5562351.298941471\n"
     ]
    }
   ],
   "source": [
    "print(np.array(costs_toudi206).sum())\n",
    "print(np.array(costs_toudi22).sum())\n",
    "print(np.array(costs_toudi21).sum())\n",
    "print(np.array(costs_lanshou).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171925"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lanshou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下代码暂时废了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-155-5b55da4b2e93>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ss['投递地址'] = ss['投递地址'].apply(str)\n"
     ]
    }
   ],
   "source": [
    "#读取投递数据1\n",
    "data_toudi21 = pd.read_csv('toudi_21.csv', encoding='gb18030', usecols=[0,1,2,3,4,7,8,10])\n",
    "data_toudi21['道段'] = data_toudi21['道段'].str.split(' ', expand=True)[0]\n",
    "data_toudi21['投递日期'] = pd.to_datetime(data_toudi21['投递日期'])\n",
    "\n",
    "data_toudi21 = data_toudi21.loc[data_toudi21['退回妥投_收件人地址'].isnull().values.tolist()]\n",
    "\n",
    "ss= data_toudi21[['投递地址','投递日期']]\n",
    "ss['投递地址'] = ss['投递地址'].apply(str)\n",
    "bool = ss['投递地址'].str.contains('四川省').values\n",
    "ss = ss[bool]\n",
    "data_toudi21 = data_toudi21.loc[ss.index,:]\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "data_toudi21.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ekips\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#暂时不用\n",
    "#揽收数据没有道段，故不划分道段\n",
    "\n",
    "#对toudi21的每个机构进行处理\n",
    "for department in toudi21:\n",
    "    department_temp = department.loc[department['lng'].isnull().values.tolist()] #不含经纬度的数据\n",
    "    department_done = department.drop(department_temp.index)\n",
    "    roads = department_temp['道段'].unique()\n",
    "    roads = roads[~pd.isnull(roads)]\n",
    "    #对某个机构中的每个道段进行处理\n",
    "    for road in roads:\n",
    "        data_road = department_done.loc[department_done['道段']==road]\n",
    "        maxy = data_road['lng'].max()\n",
    "        miny = data_road['lng'].min()\n",
    "        maxx = data_road['lat'].max()\n",
    "        minx = data_road['lat'].min()\n",
    "        temp_road = department_temp.loc[department_temp['道段']==road]\n",
    "        lng = np.random.random(len(temp_road)) * (maxy - miny) + miny\n",
    "        lat = np.random.random(len(temp_road)) * (maxx - minx) + minx\n",
    "        department_temp.loc[department_temp['道段']==road, 'lng'] = lng\n",
    "        department_temp.loc[department_temp['道段']==road, 'lat'] = lat\n",
    "    #对没有道段数据的记录，即nan值做特殊处理(取处理的最后一个道段的随机经纬度)\n",
    "    nan = department_temp.loc[department_temp['道段'].isnull().values.tolist()]\n",
    "    if len(nan) > 0:\n",
    "        lng = np.random.random(len(nan)) * (maxy - miny) + miny\n",
    "        lat = np.random.random(len(nan)) * (maxx - minx) + minx\n",
    "        department_temp.loc[nan.index, 'lng'] = lng\n",
    "        department_temp.loc[nan.index, 'lat'] = lat\n",
    "    \n",
    "    department.loc[department['lng'].isnull().values.tolist(), 'lng'] = department_temp['lng']\n",
    "    department.loc[department['lat'].isnull().values.tolist(), 'lat'] = department_temp['lat']\n",
    "    \n",
    "#对toudi22的每个机构进行处理\n",
    "for department in toudi22:\n",
    "    department_temp = department.loc[department['lng'].isnull().values.tolist()] #不含经纬度的数据\n",
    "    department_done = department.drop(department_temp.index)\n",
    "    roads = department_temp['道段'].unique()\n",
    "    roads = roads[~pd.isnull(roads)]\n",
    "    #对某个机构中的每个道段进行处理\n",
    "    for road in roads:\n",
    "        data_road = department_done.loc[department_done['道段']==road]\n",
    "        maxy = data_road['lng'].max()\n",
    "        miny = data_road['lng'].min()\n",
    "        maxx = data_road['lat'].max()\n",
    "        minx = data_road['lat'].min()\n",
    "        temp_road = department_temp.loc[department_temp['道段']==road]\n",
    "        lng = np.random.random(len(temp_road)) * (maxy - miny) + miny\n",
    "        lat = np.random.random(len(temp_road)) * (maxx - minx) + minx\n",
    "        department_temp.loc[department_temp['道段']==road, 'lng'] = lng\n",
    "        department_temp.loc[department_temp['道段']==road, 'lat'] = lat\n",
    "    #对没有道段数据的记录，即nan值做特殊处理(取处理的最后一个道段的随机经纬度)\n",
    "    nan = department_temp.loc[department_temp['道段'].isnull().values.tolist()]\n",
    "    if len(nan) > 0:\n",
    "        lng = np.random.random(len(nan)) * (maxy - miny) + miny\n",
    "        lat = np.random.random(len(nan)) * (maxx - minx) + minx\n",
    "        department_temp.loc[nan.index, 'lng'] = lng\n",
    "        department_temp.loc[nan.index, 'lat'] = lat\n",
    "    \n",
    "    department.loc[department['lng'].isnull().values.tolist(), 'lng'] = department_temp['lng']\n",
    "    department.loc[department['lat'].isnull().values.tolist(), 'lat'] = department_temp['lat']\n",
    "    \n",
    "#对toudi206的每个机构进行处理\n",
    "for department in toudi206:\n",
    "    department_temp = department.loc[department['lng'].isnull().values.tolist()] #不含经纬度的数据\n",
    "    department_done = department.drop(department_temp.index)\n",
    "    roads = department_temp['道段'].unique()\n",
    "    roads = roads[~pd.isnull(roads)]\n",
    "    #对某个机构中的每个道段进行处理\n",
    "    for road in roads:\n",
    "        data_road = department_done.loc[department_done['道段']==road]\n",
    "        maxy = data_road['lng'].max()\n",
    "        miny = data_road['lng'].min()\n",
    "        maxx = data_road['lat'].max()\n",
    "        minx = data_road['lat'].min()\n",
    "        temp_road = department_temp.loc[department_temp['道段']==road]\n",
    "        lng = np.random.random(len(temp_road)) * (maxy - miny) + miny\n",
    "        lat = np.random.random(len(temp_road)) * (maxx - minx) + minx\n",
    "        department_temp.loc[department_temp['道段']==road, 'lng'] = lng\n",
    "        department_temp.loc[department_temp['道段']==road, 'lat'] = lat\n",
    "    #对没有道段数据的记录，即nan值做特殊处理(取处理的最后一个道段的随机经纬度)\n",
    "    nan = department_temp.loc[department_temp['道段'].isnull().values.tolist()]\n",
    "    if len(nan) > 0:\n",
    "        lng = np.random.random(len(nan)) * (maxy - miny) + miny\n",
    "        lat = np.random.random(len(nan)) * (maxx - minx) + minx\n",
    "        department_temp.loc[nan.index, 'lng'] = lng\n",
    "        department_temp.loc[nan.index, 'lat'] = lat\n",
    "    \n",
    "    department.loc[department['lng'].isnull().values.tolist(), 'lng'] = department_temp['lng']\n",
    "    department.loc[department['lat'].isnull().values.tolist(), 'lat'] = department_temp['lat']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
